# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M4w5xEhFKCpOij5etGCWWbKJyrLdmmR4
"""

import streamlit as st
from langchain.chains import RetrievalQA
from langchain_huggingface import HuggingFacePipeline
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
import torch

# -------------------------
# 1. Load Vectorstore
# -------------------------
@st.cache_resource
def load_vectorstore():
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
    vectorstore = Chroma(persist_directory="chroma_db", embedding_function=embeddings)
    return vectorstore.as_retriever()

# -------------------------
# 2. Load LLM (Gemma 2B IT)
# -------------------------
@st.cache_resource
def load_llm():
    model_id = "google/gemma-2-2b-it"

    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        device_map="auto"
    )

    gen_pipeline = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=350,
        temperature=0.3,
    )

    return HuggingFacePipeline(pipeline=gen_pipeline)

# -------------------------
# 3. Build RAG Chain
# -------------------------
@st.cache_resource
def create_rag_chain():
    retriever = load_vectorstore()
    llm = load_llm()

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff"
    )
    return chain

rag = create_rag_chain()

# -------------------------
# 4. Streamlit UI
# -------------------------
st.set_page_config(page_title="RAG System", layout="wide")
st.title("ðŸ“˜ RAG Question Answering with Gemma 2B")

st.write("Ask questions based on your uploaded documents.")

# User input
query = st.text_input("Enter your question")

if st.button("Ask"):
    if query.strip() == "":
        st.warning("Please enter a question.")
    else:
        with st.spinner("Generating response..."):
            response = rag.run(query)
        st.success("Answer:")
        st.write(response)